---
title: "Datos SUBE AMBA"
author: "Tomas"
date: "21/6/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Librerías

Aca simplemente cargamos las librerias que vamos a ir usando:

```{r librerias}
library(tidyverse)
library(jsonlite)
library(geojsonio)
library(lubridate)
library(sf)
library(janitor)
```

## Datos

Estamos probando con datos de SUBE de una semana de Junio del 2019
```{r datos, echo=FALSE}
GPS <- read_delim("/Documentos//Datos Para OD/GPS/2019-06-13.csv", 
    ";", escape_double = FALSE, col_names = FALSE, 
    trim_ws = TRUE)


```

### Limpieza
vamos a ponerle bien los nombres a las columnas, 
darle un formato geoespacial

```{r}
columnas<-read_delim("/Documentos/Datos Para OD/GPS/gps_header.csv", 
    ";", escape_double = FALSE, col_names = TRUE, 
    trim_ws = TRUE)

columnas<-clean_names(columnas)
a<-colnames(columnas)
colnames(GPS)<-a

GPS<- st_as_sf(GPS, coords = c("longitude", "latitude"), crs = 4326)
```

```{r Vias principales}
vias<- read_sf("/Google Drive/00 Trabajo/MOP/DPIT/shapes/Vial/Propuesta Primaria/PRIMARIA_TRAMOS_BUSES_/PRIMARIA_TRAMOS_BUSES_.shp")
vias_sep<-mutate(vias, BUS=paste(BUS_NAC,",",BUS_PROV,",",BUS_MUN)) %>% 
  separate_rows(BUS, sep = ",") %>% 
  mutate(BUS=as.numeric(BUS)) %>% 
  filter(!is.na(BUS)) %>% 
  as.data.frame() %>% 
  select(BUS, IDTRAMO)

st_crs(vias)

vias<-st_transform(vias,5348)


buffer<-filter(vias,red_RMBA=="primaria") %>% 
               st_buffer(25) %>% 
                st_transform(4326)

```
```{r}
gps_principales<-st_intersection(GPS,buffer)

gps_principales<-select(gps_principales, codigoentidad, idlinea, interno, c_ld_id, dtsn, date_time, type, direction, status, IDTRAMO)
gps_principales<-mutate(gps_principales, date_time==date(date_time))
```
```{r}
primeros<-function(A){
    select(A, date_time, interno,idlinea, IDTRAMO) %>% 
    mutate (date_time=dmy_hms(date_time)) %>%
    arrange( interno, date_time) %>% 
    group_by(idlinea, interno, IDTRAMO) %>% 
    mutate(agrupado=(date_time-lag(date_time))/dminutes(1)) %>% 
    mutate(agrupado = if_else(is.na(agrupado),1,if_else(agrupado>20,1,0))) %>% 
    filter(agrupado==1)
  
}
```
```{r}
gps_primeros<-primeros(gps_principales)
gps_primeros<- mutate(gps_primeros, hora=hour(date_time))

REL<-read_delim("~/Datos Para OD/Otros/Relacion_Empresa-Linea.csv", 
    ";", escape_double = FALSE, trim_ws = TRUE)

REL<-mutate(REL,LINEA=parse_number(REL$LINEA)) %>% 
  filter(!is.na(LINEA)) %>% 
  select(ID_LINEA,LINEA)
gps_primeros<-left_join(gps_primeros,REL, by=c("idlinea"="ID_LINEA"))

gps_primeros_union<-left_join(gps_primeros,vias_sep)

gps_primeros_union<-filter(gps_primeros_union, BUS==LINEA)
```




### exportacion

```{r}
write_sf(gps_primeros_union,"/Documentos/Datos Para OD/GPS/2019_06_13_primeros_3.geojson")

```

### Procesamiento

Vamos a intetar limpiar algunos registros.
Dentro de los puntos que estamos detectando tambien estamos agarrando puntos de las transversales, esto puede ser especialmente problemático en la interseccion con arterias importantes.

Vamos a hacer lo siguiente:
1 vamos a armar un registro para cada par tramo-linea
2 vamos a hacer un join entre los puntos y los tramos
3 filtramos aquellos que coincida linea con 
```{r}
servicios_hora<-as.data.frame(gps_primeros_union) %>% 
                group_by(IDTRAMO,hora) %>% 
                summarise(ser_hora=n())

servicios_dia<-as.data.frame(gps_primeros_union) %>% 
                group_by(IDTRAMO) %>% 
                summarise(ser_dia=n())

write_csv(servicios_dia, "/Google Drive/00 Trabajo/MOP/DPIT/Red Metropolitana de infra/ser_dia_tramos.csv")

write_csv(servicios_hora, "/Google Drive/00 Trabajo/MOP/DPIT/Red Metropolitana de infra/ser_hora_tramos.csv")
```

